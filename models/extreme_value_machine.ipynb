{
    "cells": [{
        "cell_type":
        "code",
        "execution_count":
        1,
        "metadata": {},
        "outputs": [],
        "source": [
            "from sklearn.metrics.pairwise import pairwise_distances\n",
            "from tensorflow.keras.utils import multi_gpu_model\n",
            "from model import identity_block, conv_block\n",
            "from tensorflow.keras.models import Model\n",
            "from tensorflow.keras import optimizers\n",
            "from tensorflow.keras import layers\n", "import numpy as np\n",
            "import h5py\n", "import matplotlib.pyplot as plt"
        ]
    }, {
        "cell_type":
        "code",
        "execution_count":
        3,
        "metadata": {},
        "outputs": [],
        "source": [
            "lr=1e-4\n", "epochs=50\n", "decay=1e-2\n", "num_classes=35\n",
            "\n", "data_dir=\"data/CSI_preprocessed_35.h5\"\n",
            "intruder_dir=\"data/CSI_preprocessed_Intruder.h5\""
        ]
    }, {
        "cell_type":
        "code",
        "execution_count":
        3,
        "metadata": {},
        "outputs": [{
            "name": "stdout",
            "output_type": "stream",
            "text": ["(1189, 500, 270, 1) (200, 500, 270, 1)\n"]
        }],
        "source": [
            "hf = h5py.File(data_dir, 'r')\n",
            "X_train = np.expand_dims(hf.get('X_train'), axis=-1)\n",
            "X_test = np.expand_dims(hf.get('X_test'), axis=-1)\n",
            "y_train = np.array(hf.get('y_train'))\n",
            "y_test = np.array(hf.get('y_test'))\n",
            "y_train_onehot = np.eye(num_classes)[hf.get('y_train')]\n",
            "y_test_onehot = np.eye(num_classes)[hf.get('y_test')]\n",
            "hf.close()\n", "\n", "hf = h5py.File(intruder_dir, 'r')\n",
            "X_data = np.expand_dims(hf.get('X_data'), axis=-1)\n",
            "hf.close()\n", "\n", "print(X_train.shape, X_data.shape)"
        ]
    }, {
        "cell_type":
        "code",
        "execution_count":
        4,
        "metadata": {
            "scrolled": true
        },
        "outputs": [{
            "name":
            "stdout",
            "output_type":
            "stream",
            "text": [
                "__________________________________________________________________________________________________\n",
                "Layer (type)                    Output Shape         Param #     Connected to                     \n",
                "==================================================================================================\n",
                "input_1 (InputLayer)            (None, 500, 270, 1)  0                                            \n",
                "__________________________________________________________________________________________________\n",
                "conv2d (Conv2D)                 (None, 247, 132, 64) 3200        input_1[0][0]                    \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization (BatchNorma (None, 247, 132, 64) 256         conv2d[0][0]                     \n",
                "__________________________________________________________________________________________________\n",
                "activation (Activation)         (None, 247, 132, 64) 0           batch_normalization[0][0]        \n",
                "__________________________________________________________________________________________________\n",
                "max_pooling2d (MaxPooling2D)    (None, 123, 65, 64)  0           activation[0][0]                 \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_1 (BatchNor (None, 123, 65, 64)  256         max_pooling2d[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_1 (Activation)       (None, 123, 65, 64)  0           batch_normalization_1[0][0]      \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_1 (Conv2D)               (None, 62, 33, 64)   4160        activation_1[0][0]               \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_2 (BatchNor (None, 62, 33, 64)   256         conv2d_1[0][0]                   \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_3 (BatchNor (None, 123, 65, 64)  256         max_pooling2d[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_2 (Activation)       (None, 62, 33, 64)   0           batch_normalization_2[0][0]      \n",
                "__________________________________________________________________________________________________\n",
                "activation_3 (Activation)       (None, 123, 65, 64)  0           batch_normalization_3[0][0]      \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_2 (Conv2D)               (None, 62, 33, 256)  147712      activation_2[0][0]               \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_3 (Conv2D)               (None, 62, 33, 256)  16640       activation_3[0][0]               \n",
                "__________________________________________________________________________________________________\n",
                "concatenate (Concatenate)       (None, 62, 33, 512)  0           conv2d_2[0][0]                   \n",
                "                                                                 conv2d_3[0][0]                   \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_4 (BatchNor (None, 62, 33, 512)  2048        concatenate[0][0]                \n",
                "__________________________________________________________________________________________________\n",
                "activation_4 (Activation)       (None, 62, 33, 512)  0           batch_normalization_4[0][0]      \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_4 (Conv2D)               (None, 62, 33, 64)   32832       activation_4[0][0]               \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_5 (BatchNor (None, 62, 33, 64)   256         conv2d_4[0][0]                   \n",
                "__________________________________________________________________________________________________\n",
                "activation_5 (Activation)       (None, 62, 33, 64)   0           batch_normalization_5[0][0]      \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_5 (Conv2D)               (None, 62, 33, 256)  147712      activation_5[0][0]               \n",
                "__________________________________________________________________________________________________\n",
                "concatenate_1 (Concatenate)     (None, 62, 33, 768)  0           conv2d_5[0][0]                   \n",
                "                                                                 concatenate[0][0]                \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_6 (BatchNor (None, 62, 33, 768)  3072        concatenate_1[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_6 (Activation)       (None, 62, 33, 768)  0           batch_normalization_6[0][0]      \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_6 (Conv2D)               (None, 31, 17, 128)  98432       activation_6[0][0]               \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_7 (BatchNor (None, 31, 17, 128)  512         conv2d_6[0][0]                   \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_8 (BatchNor (None, 62, 33, 768)  3072        concatenate_1[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_7 (Activation)       (None, 31, 17, 128)  0           batch_normalization_7[0][0]      \n",
                "__________________________________________________________________________________________________\n",
                "activation_8 (Activation)       (None, 62, 33, 768)  0           batch_normalization_8[0][0]      \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_7 (Conv2D)               (None, 31, 17, 512)  590336      activation_7[0][0]               \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_8 (Conv2D)               (None, 31, 17, 512)  393728      activation_8[0][0]               \n",
                "__________________________________________________________________________________________________\n",
                "concatenate_2 (Concatenate)     (None, 31, 17, 1024) 0           conv2d_7[0][0]                   \n",
                "                                                                 conv2d_8[0][0]                   \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_9 (BatchNor (None, 31, 17, 1024) 4096        concatenate_2[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_9 (Activation)       (None, 31, 17, 1024) 0           batch_normalization_9[0][0]      \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_9 (Conv2D)               (None, 31, 17, 128)  131200      activation_9[0][0]               \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_10 (BatchNo (None, 31, 17, 128)  512         conv2d_9[0][0]                   \n",
                "__________________________________________________________________________________________________\n",
                "activation_10 (Activation)      (None, 31, 17, 128)  0           batch_normalization_10[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_10 (Conv2D)              (None, 31, 17, 512)  590336      activation_10[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "concatenate_3 (Concatenate)     (None, 31, 17, 1536) 0           conv2d_10[0][0]                  \n",
                "                                                                 concatenate_2[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_11 (BatchNo (None, 31, 17, 1536) 6144        concatenate_3[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_11 (Activation)      (None, 31, 17, 1536) 0           batch_normalization_11[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_11 (Conv2D)              (None, 16, 9, 256)   393472      activation_11[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_12 (BatchNo (None, 16, 9, 256)   1024        conv2d_11[0][0]                  \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_13 (BatchNo (None, 31, 17, 1536) 6144        concatenate_3[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_12 (Activation)      (None, 16, 9, 256)   0           batch_normalization_12[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "activation_13 (Activation)      (None, 31, 17, 1536) 0           batch_normalization_13[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_12 (Conv2D)              (None, 16, 9, 1024)  2360320     activation_12[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_13 (Conv2D)              (None, 16, 9, 1024)  1573888     activation_13[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "concatenate_4 (Concatenate)     (None, 16, 9, 2048)  0           conv2d_12[0][0]                  \n",
                "                                                                 conv2d_13[0][0]                  \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_14 (BatchNo (None, 16, 9, 2048)  8192        concatenate_4[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_14 (Activation)      (None, 16, 9, 2048)  0           batch_normalization_14[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_14 (Conv2D)              (None, 16, 9, 256)   524544      activation_14[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_15 (BatchNo (None, 16, 9, 256)   1024        conv2d_14[0][0]                  \n",
                "__________________________________________________________________________________________________\n",
                "activation_15 (Activation)      (None, 16, 9, 256)   0           batch_normalization_15[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_15 (Conv2D)              (None, 16, 9, 1024)  2360320     activation_15[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "concatenate_5 (Concatenate)     (None, 16, 9, 3072)  0           conv2d_15[0][0]                  \n",
                "                                                                 concatenate_4[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_16 (BatchNo (None, 16, 9, 3072)  12288       concatenate_5[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_16 (Activation)      (None, 16, 9, 3072)  0           batch_normalization_16[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_16 (Conv2D)              (None, 8, 5, 512)    1573376     activation_16[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_17 (BatchNo (None, 8, 5, 512)    2048        conv2d_16[0][0]                  \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_18 (BatchNo (None, 16, 9, 3072)  12288       concatenate_5[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_17 (Activation)      (None, 8, 5, 512)    0           batch_normalization_17[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "activation_18 (Activation)      (None, 16, 9, 3072)  0           batch_normalization_18[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_17 (Conv2D)              (None, 8, 5, 2048)   9439232     activation_17[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_18 (Conv2D)              (None, 8, 5, 2048)   6293504     activation_18[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "concatenate_6 (Concatenate)     (None, 8, 5, 4096)   0           conv2d_17[0][0]                  \n",
                "                                                                 conv2d_18[0][0]                  \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_19 (BatchNo (None, 8, 5, 4096)   16384       concatenate_6[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "activation_19 (Activation)      (None, 8, 5, 4096)   0           batch_normalization_19[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_19 (Conv2D)              (None, 8, 5, 512)    2097664     activation_19[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "batch_normalization_20 (BatchNo (None, 8, 5, 512)    2048        conv2d_19[0][0]                  \n",
                "__________________________________________________________________________________________________\n",
                "activation_20 (Activation)      (None, 8, 5, 512)    0           batch_normalization_20[0][0]     \n",
                "__________________________________________________________________________________________________\n",
                "conv2d_20 (Conv2D)              (None, 8, 5, 2048)   9439232     activation_20[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "concatenate_7 (Concatenate)     (None, 8, 5, 6144)   0           conv2d_20[0][0]                  \n",
                "                                                                 concatenate_6[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "global_average_pooling2d (Globa (None, 6144)         0           concatenate_7[0][0]              \n",
                "__________________________________________________________________________________________________\n",
                "dense (Dense)                   (None, 35)           215075      global_average_pooling2d[0][0]   \n",
                "__________________________________________________________________________________________________\n",
                "activation_21 (Activation)      (None, 35)           0           dense[0][0]                      \n",
                "==================================================================================================\n",
                "Total params: 38,509,091\n", "Trainable params: 38,468,003\n",
                "Non-trainable params: 41,088\n",
                "__________________________________________________________________________________________________\n",
                "Train on 1189 samples, validate on 210 samples\n",
                "Epoch 1/50\n",
                " - 17s - loss: 1.7859 - acc: 0.6030 - val_loss: 4.8846 - val_acc: 0.0286\n",
                "Epoch 2/50\n",
                " - 8s - loss: 0.3260 - acc: 0.9066 - val_loss: 5.8623 - val_acc: 0.0286\n",
                "Epoch 3/50\n",
                " - 8s - loss: 0.1360 - acc: 0.9563 - val_loss: 6.6317 - val_acc: 0.0286\n",
                "Epoch 4/50\n",
                " - 8s - loss: 0.0734 - acc: 0.9790 - val_loss: 1.4672 - val_acc: 0.4857\n",
                "Epoch 5/50\n",
                " - 8s - loss: 0.0718 - acc: 0.9739 - val_loss: 0.0558 - val_acc: 0.9762\n",
                "Epoch 6/50\n",
                " - 8s - loss: 0.0458 - acc: 0.9857 - val_loss: 0.0327 - val_acc: 0.9905\n",
                "Epoch 7/50\n",
                " - 8s - loss: 0.0522 - acc: 0.9882 - val_loss: 0.0351 - val_acc: 0.9905\n",
                "Epoch 8/50\n",
                " - 8s - loss: 0.0295 - acc: 0.9916 - val_loss: 0.0356 - val_acc: 0.9905\n",
                "Epoch 9/50\n",
                " - 8s - loss: 0.0288 - acc: 0.9924 - val_loss: 0.0454 - val_acc: 0.9810\n",
                "Epoch 10/50\n",
                " - 8s - loss: 0.0201 - acc: 0.9950 - val_loss: 0.0412 - val_acc: 0.9857\n",
                "Epoch 11/50\n",
                " - 8s - loss: 0.0276 - acc: 0.9916 - val_loss: 0.0433 - val_acc: 0.9857\n",
                "Epoch 12/50\n",
                " - 8s - loss: 0.0161 - acc: 0.9966 - val_loss: 0.0345 - val_acc: 0.9810\n",
                "Epoch 13/50\n",
                " - 8s - loss: 0.0133 - acc: 0.9983 - val_loss: 0.0377 - val_acc: 0.9810\n",
                "Epoch 14/50\n",
                " - 8s - loss: 0.0140 - acc: 0.9958 - val_loss: 0.0445 - val_acc: 0.9857\n",
                "Epoch 15/50\n",
                " - 8s - loss: 0.0103 - acc: 0.9983 - val_loss: 0.0382 - val_acc: 0.9905\n",
                "Epoch 16/50\n",
                " - 8s - loss: 0.0089 - acc: 0.9983 - val_loss: 0.0387 - val_acc: 0.9857\n",
                "Epoch 17/50\n",
                " - 8s - loss: 0.0119 - acc: 0.9975 - val_loss: 0.0438 - val_acc: 0.9857\n",
                "Epoch 18/50\n",
                " - 8s - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0175 - val_acc: 0.9952\n",
                "Epoch 19/50\n",
                " - 8s - loss: 0.0098 - acc: 0.9983 - val_loss: 0.0200 - val_acc: 0.9952\n",
                "Epoch 20/50\n",
                " - 8s - loss: 0.0093 - acc: 0.9983 - val_loss: 0.0206 - val_acc: 0.9905\n",
                "Epoch 21/50\n",
                " - 8s - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0285 - val_acc: 0.9857\n",
                "Epoch 22/50\n",
                " - 8s - loss: 0.0075 - acc: 0.9992 - val_loss: 0.0222 - val_acc: 0.9905\n",
                "Epoch 23/50\n",
                " - 8s - loss: 0.0070 - acc: 0.9992 - val_loss: 0.0218 - val_acc: 0.9905\n",
                "Epoch 24/50\n",
                " - 8s - loss: 0.0098 - acc: 0.9966 - val_loss: 0.0188 - val_acc: 0.9905\n",
                "Epoch 25/50\n",
                " - 8s - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0260 - val_acc: 0.9905\n",
                "Epoch 26/50\n",
                " - 8s - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0174 - val_acc: 0.9905\n",
                "Epoch 27/50\n",
                " - 8s - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0176 - val_acc: 0.9905\n",
                "Epoch 28/50\n",
                " - 8s - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0199 - val_acc: 0.9952\n",
                "Epoch 29/50\n",
                " - 8s - loss: 0.0066 - acc: 0.9975 - val_loss: 0.0269 - val_acc: 0.9952\n",
                "Epoch 30/50\n",
                " - 8s - loss: 0.0076 - acc: 0.9992 - val_loss: 0.0287 - val_acc: 0.9905\n",
                "Epoch 31/50\n",
                " - 8s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9905\n",
                "Epoch 32/50\n",
                " - 8s - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0360 - val_acc: 0.9810\n",
                "Epoch 33/50\n",
                " - 8s - loss: 0.0043 - acc: 0.9992 - val_loss: 0.0285 - val_acc: 0.9857\n",
                "Epoch 34/50\n",
                " - 8s - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0276 - val_acc: 0.9905\n",
                "Epoch 35/50\n",
                " - 8s - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0298 - val_acc: 0.9857\n",
                "Epoch 36/50\n",
                " - 8s - loss: 0.0071 - acc: 0.9992 - val_loss: 0.0211 - val_acc: 0.9857\n",
                "Epoch 37/50\n",
                " - 8s - loss: 0.0047 - acc: 0.9992 - val_loss: 0.0254 - val_acc: 0.9905\n",
                "Epoch 38/50\n",
                " - 8s - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0282 - val_acc: 0.9857\n",
                "Epoch 39/50\n",
                " - 8s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 0.9905\n",
                "Epoch 40/50\n",
                " - 8s - loss: 0.0044 - acc: 0.9992 - val_loss: 0.0271 - val_acc: 0.9905\n",
                "Epoch 41/50\n",
                " - 8s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9905\n",
                "Epoch 42/50\n",
                " - 8s - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0296 - val_acc: 0.9905\n",
                "Epoch 43/50\n",
                " - 8s - loss: 0.0045 - acc: 0.9992 - val_loss: 0.0273 - val_acc: 0.9905\n",
                "Epoch 44/50\n",
                " - 8s - loss: 0.0047 - acc: 0.9992 - val_loss: 0.0284 - val_acc: 0.9905\n",
                "Epoch 45/50\n",
                " - 8s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9905\n",
                "Epoch 46/50\n",
                " - 8s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9857\n",
                "Epoch 47/50\n",
                " - 8s - loss: 0.0042 - acc: 0.9992 - val_loss: 0.0327 - val_acc: 0.9857\n",
                "Epoch 48/50\n",
                " - 8s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 0.9905\n",
                "Epoch 49/50\n",
                " - 8s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9857\n",
                "Epoch 50/50\n",
                " - 8s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9905\n"
            ]
        }],
        "source": [
            "input_layer = layers.Input(shape=(X_train.shape[1:]))\n", "\n",
            "x = layers.Conv2D(64, (7, 7), strides=(2, 2))(input_layer)\n",
            "x = layers.BatchNormalization(axis=-1)(x)\n",
            "x = layers.Activation('relu')(x)\n",
            "x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n", "\n",
            "x = conv_block(x, [64, 256], \"relu\")\n",
            "x = identity_block(x, [64, 256], \"relu\")\n", "\n",
            "x = conv_block(x, [128, 512], \"relu\")\n",
            "x = identity_block(x, [128, 512], \"relu\")\n", "\n",
            "x = conv_block(x, [256, 1024], \"relu\")\n",
            "x = identity_block(x, [256, 1024], \"relu\")\n", "\n",
            "x = conv_block(x, [512, 2048], \"relu\")\n",
            "x = identity_block(x, [512, 2048], \"relu\")\n", "\n",
            "x = layers.GlobalAveragePooling2D()(x)\n",
            "x = layers.Dense(num_classes, activation=None)(x)\n",
            "x = layers.Activation('softmax')(x)\n", "\n",
            "model_base = Model(inputs=input_layer, outputs=x)\n",
            "model_base.summary()\n",
            "model = multi_gpu_model(model_base, gpus=3)\n", "\n",
            "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=lr, decay=decay), metrics=['acc'])\n",
            "history = model.fit(x=X_train, y=y_train_onehot, epochs=epochs, validation_data=(X_test, y_test_onehot), verbose=2)"
        ]
    }, {
        "cell_type":
        "code",
        "execution_count":
        5,
        "metadata": {},
        "outputs": [],
        "source": [
            "model_evm = Model(inputs=model_base.get_layer(\"input_1\").input , outputs=model_base.get_layer(\"dense\").output)"
        ]
    }, {
        "cell_type":
        "code",
        "execution_count":
        6,
        "metadata": {},
        "outputs": [],
        "source": [
            "X_evm_train = model_evm.predict(X_train)\n",
            "X_evm_test = model_evm.predict(X_test)\n",
            "X_evm_data = model_evm.predict(X_data)"
        ]
    }, {
        "cell_type":
        "code",
        "execution_count":
        7,
        "metadata": {
            "scrolled": true
        },
        "outputs": [{
            "name": "stdout",
            "output_type": "stream",
            "text": ["(1189, 35)\n"]
        }],
        "source": ["print(X_evm_train.shape)"]
    }, {
        "cell_type":
        "code",
        "execution_count":
        8,
        "metadata": {},
        "outputs": [],
        "source": [
            "#https://github.com/mlosch/python-weibullfit\n",
            "    def fit(x, iters=1000, eps=1e-6):\n", "    \"\"\"\n",
            "    Fits a 2-parameter Weibull distribution to the given data using maximum-likelihood estimation.\n",
            "    :param x: 1d-ndarray of samples from an (unknown) distribution. Each value must satisfy x > 0.\n",
            "    :param iters: Maximum number of iterations\n",
            "    :param eps: Stopping criterion. Fit is stopped ff the change within two iterations is smaller than eps.\n",
            "    :return: Tuple (Shape, Scale) which can be (NaN, NaN) if a fit is impossible.\n",
            "        Impossible fits may be due to 0-values in x.\n",
            "    \"\"\"\n", "    # fit k via MLE\n",
            "    ln_x = np.log(x+eps)\n", "    k = 1.\n", "    k_t_1 = k\n",
            "\n", "    for t in range(iters):\n", "        x_k = x ** k\n",
            "        x_k_ln_x = x_k * ln_x\n",
            "        ff = np.sum(x_k_ln_x)\n", "        fg = np.sum(x_k)\n",
            "        f = ff / fg - np.mean(ln_x) - (1. / k)\n", "\n",
            "        # Calculate second derivative d^2f/dk^2\n",
            "        ff_prime = np.sum(x_k_ln_x * ln_x)\n",
            "        fg_prime = ff\n",
            "        f_prime = (ff_prime/fg - (ff/fg * fg_prime/fg)) + (1. / (k*k))\n",
            "\n", "        # Newton-Raphson method k = k - f(k;x)/f'(k;x)\n",
            "        k -= f/f_prime\n", "\n", "        if np.isnan(f):\n",
            "            return np.nan, np.nan\n",
            "        if abs(k - k_t_1) < eps:\n", "            break\n", "\n",
            "        k_t_1 = k\n", "\n",
            "    lam = np.mean(x ** k) ** (1.0 / k)\n", "\n",
            "    return k, lam\n", "\n", "\n",
            "def psi_i_dist(dist, k_i, lambda_i):\n", "    \"\"\"\n",
            "    Gives the probability of sample inclusion\n",
            "    :param dist: Numpy vector of distances between samples\n",
            "    :param lambda_i: Scale of the Weibull fitting\n",
            "    :param k_i: Shape of the Weibull fitting\n",
            "    :return: PSI = Probability of Sample Inclusion. This is the probability that x' is included in the boundary estimated by x_i\n",
            "    \"\"\"\n",
            "    return np.exp(-(((np.abs(dist))/lambda_i)**k_i))"
        ]
    }, {
        "cell_type":
        "code",
        "execution_count":
        9,
        "metadata": {},
        "outputs": [{
            "data": {
                "text/plain": ["(1189, 2)"]
            },
            "execution_count": 9,
            "metadata": {},
            "output_type": "execute_result"
        }],
        "source": [
            "# fit weibull models\n", "tow = 50\n", "weibull_models = []\n",
            "for i in range(num_classes):\n",
            "    train_ind = np.squeeze(np.where(y_train == i))\n",
            "    D = pairwise_distances(X_evm_train[train_ind], X_evm_train, metric=\"euclidean\", n_jobs=1)\n",
            "    for j in range(D.shape[0]):\n",
            "        D_tmp = np.sort(D[j])\n",
            "        D_tmp = D_tmp[np.where(D_tmp>0)][:tow]\n",
            "        weibull_models.append(fit(D_tmp, iters=100, eps=1e-6))\n",
            "weibull_models = np.array(weibull_models)\n",
            "weibull_models.shape"
        ]
    }, {
        "cell_type":
        "code",
        "execution_count":
        10,
        "metadata": {},
        "outputs": [],
        "source": [
            "# get extreme value machine perdictions\n",
            "def get_evm(data):\n",
            "    D = pairwise_distances(X_evm_train, data, metric=\"euclidean\", n_jobs=1)\n",
            "    preds = np.zeros_like(D)\n",
            "    for i in range(X_evm_train.shape[0]):\n",
            "        for j in range(data.shape[0]):\n",
            "            preds[i, j] = psi_i_dist(D[i, j], weibull_models[i][0], weibull_models[i][1])\n",
            "    return preds"
        ]
    }, {
        "cell_type":
        "code",
        "execution_count":
        11,
        "metadata": {},
        "outputs": [{
            "data": {
                "text/plain": ["99.04761904761905"]
            },
            "execution_count": 11,
            "metadata": {},
            "output_type": "execute_result"
        }],
        "source": [
            "evm = get_evm(X_evm_test)\n",
            "np.mean(np.equal(y_train[np.argmax(evm, axis=0)], y_test))*100"
        ]
    }, {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": []
    }],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.2"
        }
    },
    "nbformat":
    4,
    "nbformat_minor":
    4
}
